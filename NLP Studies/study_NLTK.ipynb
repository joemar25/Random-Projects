{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0454ecd3",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align: center\">Natural Language Toolkit (NLTK)</h1>\n",
    "<p> \n",
    "    is a leading platform for building Python programs to work with human language data. It provides easy-to-use interfaces to over <u>over 50 corpora and lexical resources</u> such as WordNet, along with a suite of text processing for classification, tokenization, stemming, tagging, parsing, and semantic reasoning, wrappers for industrial-strength NLP Libriaries, and an active <u>discussion forum</u>.\n",
    "</p>\n",
    "<br>\n",
    "<h3>Installation</h3>\n",
    "<ul>\n",
    "    <li>pip install nltk</li>\n",
    "    or\n",
    "    <li>conda install -c anaconda nltk</li>\n",
    "</ul>\n",
    "<br>\n",
    "<h3>NLTK data installation</h3>\n",
    "<p>\n",
    "    NLTK comes with many corpora, toy grammars, trained models, etc. A complete list is posted at <a href='https://www.nltk.org/nltk_data/'>NLTK main page (nltk data)</a>\n",
    "</p>\n",
    "```python\n",
    "    import nltk\n",
    "    nltk.download()\n",
    "```\n",
    "<p>that will lunch the nltk downloader gui, from which you can download corpus</p>\n",
    "<img title=\"a title\" alt=\"Alt Image\" src=\"src/img/nltk downloader.PNG\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff28ea5f",
   "metadata": {},
   "source": [
    "<h2>Start...</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b397ec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: nltk in c:\\programdata\\anaconda3\\lib\\site-packages (3.7)\n",
      "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk) (4.64.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk) (2022.7.9)\n",
      "Requirement already satisfied: joblib in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk) (1.1.0)\n",
      "Requirement already satisfied: click in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4996b2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0d758eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download() # uncomment to see the gui, comment if you wish not to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8aa46f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"Monticello wasn't designated as UNESCO World Heritage Site until 1987 \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c3ae68f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Monticello wasn't designated as UNESCO World Heritage Site until 1987 \""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text # display text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9eb165e",
   "metadata": {},
   "source": [
    "<b>better word tokenizers</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e9396698",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Monticello',\n",
       " \"wasn't\",\n",
       " 'designated',\n",
       " 'as',\n",
       " 'UNESCO',\n",
       " 'World',\n",
       " 'Heritage',\n",
       " 'Site',\n",
       " 'until',\n",
       " '1987',\n",
       " '']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import regex\n",
    "regex.split(\"[\\s\\.\\,]\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eee2e2d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Monticello',\n",
       " 'was',\n",
       " \"n't\",\n",
       " 'designated',\n",
       " 'as',\n",
       " 'UNESCO',\n",
       " 'World',\n",
       " 'Heritage',\n",
       " 'Site',\n",
       " 'until',\n",
       " '1987']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.word_tokenize(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200b54d7",
   "metadata": {},
   "source": [
    "Notice that \"wasn't\" is separated as \"was\" and \"n't\" in which can be efficient in some cases. Also, the empty space is not included."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9b1bcd",
   "metadata": {},
   "source": [
    "<h2 style=\"text-align: center\">Stemming</h2>\n",
    "<p style=\"text-align: center\">there are multiple stemmers in nltk, let's investigate them!</p>\n",
    "\n",
    "<h3>Porter Stemming</h3>\n",
    "<p>it applies some rules on the text, you can check the rules <a href='https://www.nltk.org/api/nltk.stem.porter.html'>here</a>.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fe1cf425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Armies >>>> armi\n",
      "Children >>>> children\n",
      "Essays >>>> essay\n",
      "Baby >>>> babi\n",
      "Bamboos >>>> bamboo\n",
      "Benches >>>> bench\n",
      "Birds >>>> bird\n",
      "Boats >>>> boat\n",
      "Bones >>>> bone\n",
      "Boxes >>>> box\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "p_stemmer = PorterStemmer()\n",
    "\n",
    "# Read more: https://onlymyenglish.com/plural-noun-list/\n",
    "plurals = [\n",
    "    'Armies', 'Children' ,'Essays', 'Baby', 'Bamboos', 'Benches', 'Birds' ,'Boats' ,'Bones', 'Boxes'\n",
    "]\n",
    "\n",
    "for word in plurals:\n",
    "    print(f'{word} >>>> {p_stemmer.stem(word)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d3b3a8",
   "metadata": {},
   "source": [
    "Note: This algorithm for stemming is ok to use, but there are other stemming algorithm like SnowballStemming is better and far more convinient.\n",
    "\n",
    "<h3>Snowball Stemming</h3>\n",
    "<p>it supports multiple languages</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3b87e6a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('arabic',\n",
       " 'danish',\n",
       " 'dutch',\n",
       " 'english',\n",
       " 'finnish',\n",
       " 'french',\n",
       " 'german',\n",
       " 'hungarian',\n",
       " 'italian',\n",
       " 'norwegian',\n",
       " 'porter',\n",
       " 'portuguese',\n",
       " 'romanian',\n",
       " 'russian',\n",
       " 'spanish',\n",
       " 'swedish')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "SnowballStemmer.languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "36286a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "sn_stemmer = SnowballStemmer('english') # we use English in which far superior than Porter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "678b529a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'generous'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sn_stemmer.stem('generously')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6322f0db",
   "metadata": {},
   "source": [
    "compare to...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bc335d91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gener'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_stemmer.stem('generously')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349c0bd3",
   "metadata": {},
   "source": [
    "See, you can judge the result.\n",
    "<br>\n",
    "<h3>Lemmatization</h3>\n",
    "<p>retrieving the source of the word</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7d179980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Armies >>>> Armies\n",
      "Children >>>> Children\n",
      "Essays >>>> Essays\n",
      "Baby >>>> Baby\n",
      "Bamboos >>>> Bamboos\n",
      "Benches >>>> Benches\n",
      "Birds >>>> Birds\n",
      "Boats >>>> Boats\n",
      "Bones >>>> Bones\n",
      "Boxes >>>> Boxes\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "for word in plurals:\n",
    "    print(f'{word} >>>> {lemmatizer.lemmatize(word)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "536d7509",
   "metadata": {},
   "source": [
    "<h3>Summary!</h3>\n",
    "<ul>\n",
    "    <li>installed NLTK and it's data</li>\n",
    "    <li>used NLTK tokenizers</li>\n",
    "    <li>used NLTK Stemmers</li>\n",
    "    <li>used NLTK Lemmatizers</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e9e085e",
   "metadata": {},
   "source": [
    "sources\n",
    "<br>\n",
    "intro: https://www.youtube.com/watch?v=WYge0KZBhe0&ab_channel=ProgrammingKnowledge"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
